# ‚è±Ô∏è Timing Breakdown - Guia Completo

## O que foi adicionado

### 1. **Backend** - C√°lculo detalhado de timing

**Arquivo**: `pages/api/agente/chat.ts`

Agora o backend calcula e salva:
- **Total time**: Tempo total da resposta
- **LLM thinking time**: Tempo que o GPT-5-nano passou "pensando"
- **Tool execution time**: Tempo consultando o banco de dados (soma de todas as queries)
- **Tools count**: Quantas queries foram executadas

**Exemplo de log**:
```
[AGENT DEBUG] Tempo total: 68737ms
  - LLM thinking: 67917ms (98.8%)
  - Tool execution: 820ms (1.2%)
[AGENT DEBUG] Tool calls feitas: 5
```

### 2. **Database** - Nova coluna `timing_breakdown`

**Migration**: `029_agent_timing_breakdown.sql`

Adiciona coluna JSONB na tabela `agent_messages`:

```sql
{
  "total_time_ms": 68737,
  "llm_thinking_ms": 67917,
  "tool_execution_ms": 820,
  "tools_count": 5
}
```

### 3. **Frontend** - √çcone (i) com tooltip

**Arquivo**: `components/agente/ChatMessage.tsx`

Adicionado √≠cone **Info (i)** ao lado do bot√£o "Copiar":
- Aparece apenas em mensagens do assistente
- Mostra tooltip no hover com:
  - **Tokens**: Input e Output
  - **Tempo total**: Dura√ß√£o completa
  - **LLM pensando**: Quanto tempo o GPT-5 gastou "pensando" (% do total)
  - **Consultando BD**: Tempo das queries SQL (% do total)
  - **Queries executadas**: Quantidade de tool calls

**Visual do tooltip**:
```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ Tokens                      ‚îÇ
‚îÇ Input:     102,094          ‚îÇ
‚îÇ Output:      6,293          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Tempo                68.7s  ‚îÇ
‚îÇ LLM pensando:    67.9s (99%)‚îÇ
‚îÇ Consultando BD:  0.8s  (1%) ‚îÇ
‚îÇ Queries executadas: 5       ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Problema identificado

Nos logs do usu√°rio:
- **Tempo total**: 68.7 segundos ‚è±Ô∏è
- **Tempo de SQL**: 0.8 segundos (820ms)
- **Tempo "pensando"**: **67.9 segundos** ü§î

**98.8% do tempo** foi o GPT-5-nano "pensando", n√£o as queries!

### Por que isso acontece?

1. **Cold start** do modelo - Primeira request ap√≥s inatividade
2. **Rate limiting** da OpenAI - Throttling de velocidade
3. **Lat√™ncia de rede** - Conex√£o lenta com a API
4. **Modelo pensando** - GPT-5-nano pode ser mais lento que GPT-4o em alguns casos

### Poss√≠veis solu√ß√µes

1. **Usar streaming mais agressivo** - J√° est√° habilitado, mas pode otimizar
2. **Reduzir recursion_limit** - De 25 para 15 (menos itera√ß√µes do agente)
3. **Prompt mais direto** - Reduzir instru√ß√µes complexas
4. **Cache de prompt** - OpenAI cacheia automaticamente prompts >1024 tokens
5. **Verificar lat√™ncia da API** - Pode ser problema de rede

## Como executar

### 1. Execute a migration no Supabase

```bash
# Abra o Supabase SQL Editor
# Cole TODO o conte√∫do de database/EXECUTAR_NO_SUPABASE.sql
# Clique em "Run"
```

O script j√° inclui:
- ‚úÖ Migration 027 (recursion_limit)
- ‚úÖ Migration 028 (gpt-5-nano default)
- ‚úÖ Migration 029 (timing_breakdown)

### 2. Fa√ßa deploy

```bash
git add .
git commit -m "feat: add timing breakdown with (i) tooltip showing LLM vs DB time"
git push origin master
```

### 3. Teste no frontend

1. V√° para `/agente`
2. Fa√ßa uma pergunta
3. Aguarde a resposta
4. **Passe o mouse sobre o √≠cone (i)** ao lado do "Copiar"
5. Veja o breakdown detalhado de timing!

## Arquivos modificados

### Backend
- `pages/api/agente/chat.ts` - C√°lculo de timing breakdown
- `types/index.ts` - Interface `AgentTimingBreakdown`

### Frontend
- `components/agente/ChatMessage.tsx` - √çcone (i) com tooltip

### Database
- `database/migrations/029_agent_timing_breakdown.sql` - Nova coluna
- `database/EXECUTAR_NO_SUPABASE.sql` - Script completo atualizado

## Exemplo real

**Pergunta**: "Qual o lucro do cliente IELENPET?"

**Timing breakdown**:
```
Total: 68.7s
‚îú‚îÄ LLM pensando:    67.9s (98.8%)  ‚ö†Ô∏è MUITO LENTO!
‚îî‚îÄ Consultando BD:   0.8s  (1.2%)  ‚úÖ R√°pido

Queries executadas: 5
- SELECT id, nome FROM clientes_fornecedores... (290ms)
- SELECT v.*, cf.* FROM vendas... (70ms)
- SELECT SUM(lucro)... (67ms)
- etc.
```

## Pr√≥ximos passos (otimiza√ß√£o)

1. **Investigar lat√™ncia da OpenAI API**
   - Medir tempo de network vs tempo de processamento
   - Testar em diferentes hor√°rios

2. **Prompt caching**
   - Verificar se o cache est√° sendo usado
   - System prompt (~10k tokens) deveria ser cachado

3. **Reduzir recursion_limit**
   - Testar com 15 em vez de 25
   - Menos itera√ß√µes = mais r√°pido

4. **Comparar com GPT-4o**
   - Ser√° que o GPT-4o √© mais r√°pido?
   - Trade-off: custo vs velocidade

5. **Streaming optimization**
   - Verificar se SSE est√° otimizado
   - Buffer size adequado?

---

Feito! üéâ Agora voc√™ pode ver exatamente onde o tempo est√° sendo gasto.
